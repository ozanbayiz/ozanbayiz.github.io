---
title: "VISTA: Vision Intersectional Sparse Trait Analysis"
shortTitle: "VISTA"
description: "Probed Vision Encoders with linear classifiers and trained patch-level SAEs to discover interpretable sparse dictionary features (SDFs) defining demographic traits, revealing the heavy influence of reconstruction error in SAE-based debiasing."
thumbnail: "/projects/vista/thumbnail.png"
heroImage: "/projects/vista/thumbnail.png"
gitUrl: "https://github.com/ozanbayiz/vista"
date: "2025-05-11"
pdfUrl: "https://drive.google.com/file/d/1GGZpM5Wz_wwaz6jEWMMBS_Ixga-qs3XV/view?usp=drive_link"
featured: true
---

UC Berkeley, Spring 2025

<SectionDivider />

<a id="abstract" />
## Abstract

Modern Vision Language Models (VLMs) construct rich internal representations from input images. However, when these models process humans, they often inherently capture and act upon sensitive demographic attributes such as race, age, and gender—attributes that can inadvertently propagate harmful dataset biases.

**VISTA** (Vision Intersectional Sparse Trait Analysis) investigates exactly how these attributes are encoded within the Vision Encoder (VE) latents of VLMs. We train **Sparse Autoencoders (SAEs)** across various VLM vision backbones (including PaliGemma2, Qwen2-VL, and Qwen3-VL) to decompose these dense activations into discrete, interpretable **Sparse Dictionary Features (SDFs)**. 

Through rigorous causal intervention—such as suppressing or steering these demographic SDFs—we investigate whether models can be effectively "debiased." Crucially, our findings demonstrate a major confound in prior works: **SAE Reconstruction Error often dominates targeted suppression**, artificially inflating perceived fairness improvements. By setting up strict intervention typologies, VISTA sets a new standard for evaluating representational debiasing.

<SectionDivider />

<a id="linear-probing" />
## Establishing the Baseline: Linear Probing

Our first step is to mathematically confirm that demographic information is linearly decodable from standard VE latents. Consider an input image $X_{\text{img}}$ passed through a Vision Encoder, producing patch-level features:

$$
\text{VE}(X_{\text{img}}) = Z_{\text{img}} \in \mathbb{R}^{N_{\text{patches}} \times D_{\text{patch}}}
$$

To train simple linear diagnostic probes, we compute the spatial mean across the patch dimension, yielding a single vector for the entire image:

$$
\text{mean}(Z_{\text{img}}) = \bar{z}_{\text{img}} \in \mathbb{R}^{D_{\text{patch}}}
$$

Using the **FairFace dataset** (which is structurally balanced across seven race groups, genders, and age brackets), we trained linear classifiers to extract these traits. 

<Figure src="/projects/vista/LP_training.png" alt="Linear probing pipeline" caption="Visual representation of the Linear Probing pipeline. Max-pooled spatial features are fed into linear classifiers to predict demographics." />

Despite the spatial collapse from mean-pooling, the probes recovered demographic labels with dramatic accuracy well above random chance, unequivocally demonstrating that VE latents deeply entangle sensitive traits.

<Figure src="/projects/vista/LP_performance.png" alt="Linear probe validation results" caption="Ablation evaluation of the Linear Probes on the validation set." />

<SectionDivider />

<a id="sae-training" />
## Decomposing Activations with Sparse Autoencoders

To move from mere "prediction" to true "interpretability," VISTA uses Sparse Autoencoders to detangle the $\bar{z}_{\text{img}}$ vectors. We primarily utilize the **BatchTopK SAE** architecture mapping a $d$-dimensional input to a $4d$-dimensional sparse code via:

$$
\mathbf{z} = \text{TopK}\bigl(\text{ReLU}(\mathbf{W}_{\text{enc}}\,\mathbf{x} + \mathbf{b}_{\text{enc}}),\; k\bigr)
$$
$$
\hat{\mathbf{x}} = \mathbf{W}_{\text{dec}}\,\mathbf{z} + \mathbf{b}_{\text{dec}}
$$

Where the $\text{TopK}(\cdot, k)$ operation retains only the $k$ largest activations across the batch, dynamically allocating sparsity to features based on specific image complexity.

<Figure src="/projects/vista/SAE_training.png" alt="SAE training pipeline" caption="Patch-level SAE architecture. Continuous dense vectors are funnelled through a Top-K bottleneck to derive monosemantic, sparse dictionary features." />

### The Three-Stage SDF Discovery Pipeline
To isolate demographic-specific SDFs from the thousands of learned dictionary features, we execute a rigorous, intersectional filtering pipeline:

1. **Activation Frequency**: Features must activate for $>10\%$ of samples within at least one core demographic class.
2. **Mean-Activation Strength**: Candidate features are ranked by the ratio of their highest class-conditional mean activation to their lowest. We retain the top 50 discriminative features per class.
3. **Entropy Filtering**: The selected features are evaluated via Shannon Entropy. We favor features with low label entropy, indicating they act as "pure" monosemantic representations of a singular demographic segment rather than broad, heavily entangled abstractions.

<SectionDivider />

<a id="causal-interventions" />
## Causal Interventions & Methodologies

Having identified target SDFs, VISTA performs causal mediation analysis during the VLM's generative inference. We intercept the vision encoder output before it hits the language modeling head, applying six distinct intervention regimes.

1. **Noise Perturbation**: We add Gaussian noise $\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \sigma^2\mathbf{I})$ where $\sigma$ matches the magnitude of standard SAE reconstruction error.
2. **SAE Passthrough**: Activations are encoded and decoded through the SAE *without modifying features*. This measures the isolated impact of the SAE's lossy reconstruction bottleneck on VLM performance.
3. **Random Feature Suppression**: Randomly selected, non-SDF features are zeroed out as a control against arbitrary dimensionality reduction.
4. **Targeted SDF Suppression**: The explicitly identified demographic SDFs are zeroed: $z_i = 0 \; \forall i \in \mathcal{S}_{\text{attr}}$.
5. **LEACE Erasure**: A Least-squares Concept Erasure projector is fit to the latents and applied to completely subtract the linear subspace associated with a concept, bypassing SAE reconstruction entirely.
6. **S\&P Top-K Projection**: The SAE encoder weights corresponding to the top SDFs define a concept direction, and all incoming latents are orthogonally projected away from this vector.

<SectionDivider />

<a id="evaluation-findings" />
## Evaluation & Key Discoveries

We subjected the modified VLMs to free-form **Image Captioning** (measuring the Demographic Classification Rate, DCR, and BERTScore semantic preservation) and **Visual Question Answering (VQA)**.

### The Reconstruction Error Dominance
The most striking insight yielded by VISTA involves the **SAE Passthrough** baseline. Previous literature has heralded targeted SDF suppression as a potent debiasing tool. However, VISTA demonstrates that merely passing latents through the SAE without modifying *any* features triggers nearly the exact same drop in demographic focus as specifically suppressing SDFs. 

This indicates that **Reconstruction Error**, rather than highly surgical concept ablation, is frequently responsible for the "debiasing" effect observed in downstream VLMs. The lossy $L_0$ bottleneck drops high-frequency texture and semantic nuances, inherently "blurring" demographic clarity to the language model. 

### Stereotypes as Semantic Features
In examining the discovered SDFs directly, we observed that Vision Encoders heavily proxy demographic attributes using cultural attire and stylistic markers—features completely detached from base physiological traits.

<Figure src="/projects/vista/neckbeard_feature.jpg" alt="A feature associated with sunglasses" caption="Some SDFs successfully isolate purely semantic objects like sunglasses, entirely divorced from demographics."/>

However, when searching for high-correlation demographic SDFs, the most prominent features often locked onto societal stereotypes and religious garments:

<ImageGrid>
<Figure src="/projects/vista/stereotype_feature1.png" alt="Headscarves activate a race-associated feature" caption="A specific 'race' SDF strongly activates on headscarves, acting as a lazy demographic proxy." />
<Figure src="/projects/vista/stereotype_feature2.png" alt="Beards activate a race-associated feature" caption="Another SDF treats prominent facial hair styles as primary indicators for demographic traits." />
</ImageGrid>

<SectionDivider />

<a id="conclusion" />
## Conclusion

VISTA underscores that while Sparse Autoencoders offer a mesmerizing window into the black-box representations of Vision-Language Models, utilizing them directly for active debiasing is incredibly fraught. Interventions must be rigidly baselined against reconstruction loss, as the simple act of sparse compression strips away demographic subtleties. 

Future ML safety efforts must focus on either developing highly lossless Matryoshka-style SAEs, or employing direct spatial-projection techniques (like LEACE) to erase concepts without globally damaging the latent representation.
