CS 180: Intro to Computer Vision and Computational Photography, Project 4, Fall 2024

<SectionDivider />

<a id="photos" />
## Part 1: Shoot the Pictures

I took photos of mannequins at a store.

<ImageGrid>
<Figure src="/projects/cs180/proj4/raw/1a.jpeg" alt="raw 1a" />
<Figure src="/projects/cs180/proj4/raw/1b.jpeg" alt="raw 1b" />
<Figure src="/projects/cs180/proj4/raw/2a.jpeg" alt="raw 2a" />
<Figure src="/projects/cs180/proj4/raw/2b.jpeg" alt="raw 2b" />
<Figure src="/projects/cs180/proj4/raw/3a.jpeg" alt="raw 3a" />
<Figure src="/projects/cs180/proj4/raw/3b.jpeg" alt="raw 3b" />
<Figure src="/projects/cs180/proj4/raw/4a.jpeg" alt="raw 4a" />
<Figure src="/projects/cs180/proj4/raw/4b.jpeg" alt="raw 4b" />
<Figure src="/projects/cs180/proj4/raw/5a.jpeg" alt="raw 5a" />
<Figure src="/projects/cs180/proj4/raw/5b.jpeg" alt="raw 5b" />
<Figure src="/projects/cs180/proj4/raw/6a.jpeg" alt="raw 6a" />
<Figure src="/projects/cs180/proj4/raw/6b.jpeg" alt="raw 6b" />
</ImageGrid>

<SectionDivider />

<a id="homographies" />
## Part 2: Recover Homographies

Applying a homography reduces to a matrix multiplication:

$$
w \begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix} 
= \begin{bmatrix} a & b & c \\ d & e & f \\ g & h & 1 \end{bmatrix} 
\begin{bmatrix} x \\ y \\ 1 \end{bmatrix} 
$$

Expanding and rearranging yields the linear system:

$$
\begin{bmatrix}
x_1 & y_1 & 1 & 0 & 0 & 0 & -x_1x_1' & -x_1y_1' \\
0 & 0 & 0 & x_1 & y_1 & 1 & -y_1x_1' & -y_1y_1' \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
x_n & y_n & 1 & 0 & 0 & 0 & -x_nx_n' & -x_ny_n' \\
0 & 0 & 0 & x_n & y_n & 1 & -y_nx_n' & -y_ny_n'
\end{bmatrix}
\begin{bmatrix} a \\ b \\ c \\ d \\ e \\ f \\g \\ h \end{bmatrix}
=
\begin{bmatrix} x_1' \\ y_1' \\ \vdots \\ x_n' \\ y_n' \end{bmatrix}
$$

Given $n$ correspondences, the homography parameters are solved via least squares.

<SectionDivider />

<a id="warping" />
## Part 3: Warp the Images

To warp an image, I applied the homography to the image corners to compute the bounding box of the warped result. Border points of the warped image can be negative, requiring an offset to keep all indices non-negative.

I created indices for the destination image, applied the inverse offset and inverse homography to map them back to the source image, and interpolated with `scipy.interpolate.RectBivariateSpline`.

<SectionDivider />

<a id="rectification" />
## Part 4: Image Rectification

<ImageGrid>
<Figure src="/projects/cs180/proj4/rect1a.png" alt="rectification 1a" />
<Figure src="/projects/cs180/proj4/rect1b.png" alt="rectification 1b" />
</ImageGrid>

<ImageGrid>
<Figure src="/projects/cs180/proj4/rect2a.png" alt="rectification 2a" />
<Figure src="/projects/cs180/proj4/rect2b.png" alt="rectification 2b" />
</ImageGrid>

<SectionDivider />

<a id="mosaic" />
## Part 5: Blend the Images into a Mosaic

I implemented blending with a two-level Laplacian pyramid. The mask was generated from the distance transform of each image's polygon (using `cv2.fillPoly` and `cv2.distanceTransform`), and the blending weights were computed as the ratio of the two distance transforms.

<Figure src="/projects/cs180/proj4/matched_features.png" alt="matched features" caption="Matched feature correspondences between two images." />

<ImageGrid>
<Figure src="/projects/cs180/proj4/blend_mask.png" alt="blend mask" />
<Figure src="/projects/cs180/proj4/blend_hf.png" alt="blend high frequency" />
<Figure src="/projects/cs180/proj4/blend_lf.png" alt="blend low frequency" />
</ImageGrid>

<ImageGrid>
<Figure src="/projects/cs180/proj4/blend_final.png" alt="blend final" />
<Figure src="/projects/cs180/proj4/blend_annotated.png" alt="blend annotated" />
</ImageGrid>

---

### Part 5.X: Manual Correspondences

Automatic feature matching did not always succeed, requiring manual correspondences for some image pairs.

<Figure src="/projects/cs180/proj4/truth_hurts.png" alt="truth hurts" caption="Manual correspondences were ultimately required." />

<ImageGrid>
<Figure src="/projects/cs180/proj4/manual_correspondences1.png" alt="manual correspondences 1" />
<Figure src="/projects/cs180/proj4/manual_correspondences2.png" alt="manual correspondences 2" />
<Figure src="/projects/cs180/proj4/manual_correspondences3.png" alt="manual correspondences 3" />
</ImageGrid>

<ImageGrid>
<Figure src="/projects/cs180/proj4/manual_mosaic1.png" alt="manual mosaic 1" />
<Figure src="/projects/cs180/proj4/manual_mosaic2.png" alt="manual mosaic 2" />
<Figure src="/projects/cs180/proj4/manual_mosaic3.png" alt="manual mosaic 3" />
</ImageGrid>

<SectionDivider />

<a id="corners" />
## Part 6: Detecting Corner Features

I used the Harris corner detector and applied Adaptive Non-Maximal Suppression (ANMS) to select a spatially well-distributed subset. ANMS assigns each corner $i$ a suppression radius:

$$
r_i = \min_{j} \| \mathbf{x}_i - \mathbf{x}_j \| \quad \text{s.t.} \quad h(\mathbf{x}_j) > c_{\text{robust}} \cdot h(\mathbf{x}_i)
$$

where $h(\mathbf{x})$ is the Harris response and $c_{\text{robust}} = 0.9$. Corners are sorted by $r_i$ in decreasing order and the top 500 are kept. K-D Trees accelerated the nearest-neighbor queries.

<ImageGrid>
<Figure src="/projects/cs180/proj4/corners1a.png" alt="corners 1a" caption="Top 500 Harris corners after ANMS (image 1a)." />
<Figure src="/projects/cs180/proj4/corners1b.png" alt="corners 1b" caption="Top 500 Harris corners after ANMS (image 1b)." />
</ImageGrid>

<ImageGrid>
<Figure src="/projects/cs180/proj4/corners2a.png" alt="corners 2a" caption="Top 500 Harris corners after ANMS (image 2a)." />
<Figure src="/projects/cs180/proj4/corners2b.png" alt="corners 2b" caption="Top 500 Harris corners after ANMS (image 2b)." />
</ImageGrid>

<SectionDivider />

<a id="descriptors" />
## Part 7: Extracting Feature Descriptors

I extracted $(8s) \times (8s)$ pixel patches centered around each ANMS corner, downsampled each patch by taking every $s$th pixel, and normalized each to zero mean and unit variance.

<Figure src="/projects/cs180/proj4/feature_descriptors.png" alt="feature descriptors" caption="Normalized feature descriptor patches." />

<SectionDivider />

<a id="matching" />
## Part 8: Matching Features Between Images

For every descriptor in image $x$, I found the two most similar descriptors in image $y$ and applied Lowe's ratio test:

$$
r = \frac{\| d_x - d_{y,1} \|}{\| d_x - d_{y,2} \|}
$$

A match is accepted only if $r < \tau$ ($\tau \approx 0.4$). A low ratio indicates a distinctive correspondence. I cross-validated by checking symmetry of matches.

<ImageGrid>
<Figure src="/projects/cs180/proj4/fm1.png" alt="feature matching 1" />
<Figure src="/projects/cs180/proj4/fm2.png" alt="feature matching 2" />
<Figure src="/projects/cs180/proj4/fm3.png" alt="feature matching 3" />
</ImageGrid>

<SectionDivider />

<a id="ransac" />
## Part 9: RANSAC

RANSAC removes outlier correspondences:

1. Randomly sample 4 correspondences.
2. Compute the homography $H$ from these 4 point pairs.
3. Apply $H$ to all source points and compute reprojection error: $e_i = \| H p_i - p_i' \|$.
4. Count inliers: points where $e_i < \epsilon$ ($\epsilon = 3$ px).
5. Repeat for $N$ iterations and keep the largest inlier set.
6. Recompute $H$ from all inliers using least squares.

<ImageGrid>
<Figure src="/projects/cs180/proj4/ransac1a.png" alt="RANSAC 1a" />
<Figure src="/projects/cs180/proj4/ransac1b.png" alt="RANSAC 1b" />
</ImageGrid>

<SectionDivider />

<a id="more-mosaics" />
## Part 10: More Mosaics

All stitched mosaics:

<ImageGrid>
<Figure src="/projects/cs180/proj4/mosaic1.png" alt="mosaic 1" />
<Figure src="/projects/cs180/proj4/mosaic2.png" alt="mosaic 2" />
<Figure src="/projects/cs180/proj4/mosaic3.png" alt="mosaic 3" />
<Figure src="/projects/cs180/proj4/mosaic4.png" alt="mosaic 4" />
<Figure src="/projects/cs180/proj4/mosaic6.png" alt="mosaic 6" />
<Figure src="/projects/cs180/proj4/blend_final.png" alt="blend final" />
</ImageGrid>

Comparison of automatic vs. manual correspondences:

<ImageGrid>
<Figure src="/projects/cs180/proj4/automatic_mosaic1_labeled.png" alt="automatic mosaic 1" />
<Figure src="/projects/cs180/proj4/manual_mosaic1_labeled.png" alt="manual mosaic 1" />
</ImageGrid>

<ImageGrid>
<Figure src="/projects/cs180/proj4/automatic_mosaic2_labeled.png" alt="automatic mosaic 2" />
<Figure src="/projects/cs180/proj4/manual_mosaic2_labeled.png" alt="manual mosaic 2" />
</ImageGrid>

<ImageGrid>
<Figure src="/projects/cs180/proj4/automatic_mosaic3_labeled.png" alt="automatic mosaic 3" />
<Figure src="/projects/cs180/proj4/manual_mosaic3_labeled.png" alt="manual mosaic 3" />
</ImageGrid>

<SectionDivider />

<a id="reflections" />
## Reflections

The math underlying perspective warps is simple given how drastically the image changes after warping. The hardest part was the blending step: calculating the bounding box of the stitched image, the offset to avoid negative indices, and creating the blending mask.

---

### Extra: Panorama Viewer

I used `cv2.Stitcher` and an HTML viewer to create a [360° panorama viewer](/projects/cs180/proj4/room_viewer.html).

<Figure src="/projects/cs180/proj4/room_panorama.jpg" alt="room panorama" caption="Stitched 360° panorama used by the viewer." />
