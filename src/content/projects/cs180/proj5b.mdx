---
title: "Diffusion Models from Scratch!"
shortTitle: "Diffusion from Scratch"
description: "Training UNets: unconditional, time-conditioned, and class-conditioned; results and samples."
thumbnail: "/projects/cs180/proj5b/thumbnail.jpeg"
heroImage: "/projects/cs180/proj5b/thumbnail.jpeg"
gitUrl: "https://github.com/ozanbayiz/cs180"
date: "2024-11-19"
---

CS 180: Intro to Computer Vision and Computational Photography, Project 5B, Fall 2024

<SectionDivider />

<a id="single-step" />
## Part 1: Training a Single-Step Denoising U-Net

---

<a id="unet" />
### 1.1 Implementing the U-Net

I implemented an unconditional U-Net with the architecture provided in the project spec.

<Figure src="/projects/cs180/proj5b/backbones/unconditional_arch.png" alt="Unconditional U-Net architecture" caption="Unconditional U-Net architecture." />
<Figure src="/projects/cs180/proj5b/backbones/atomic_ops_new.png" alt="Atomic operations block" caption="Blocks that compose the backbone." />

---

<a id="denoiser" />
### 1.2 Using the U-Net to Train a Denoiser

Given a clean image $x$, I noised it to get $z = x + \sigma \epsilon$, where $\epsilon \sim \mathcal{N}(0, 1)$, and $\sigma \in \{0.0, 0.2, 0.4, 0.6, 0.8, 1.0\}$.

<Figure src="/projects/cs180/proj5b/uncond/noising_process.png" alt="Noising process" caption="Forward noising process for constructing $(\mathbf{x}, \mathbf{z})$ pairs." />

I created a dataloader producing batches of $(x, z)$ pairs with $\sigma = 0.5$.

<Figure src="/projects/cs180/proj5b/uncond/noising_dataloader.png" alt="Noising dataloader" caption="Noising dataloader output for $\sigma = 0.5$." />

#### 1.2.1 Training

I trained the U-Net to predict the noise $\epsilon_{\sigma} = z - x$, optimizing $\| \epsilon_{\sigma}  - \hat{\epsilon}\|^2$.

<Figure src="/projects/cs180/proj5b/uncond/uncond_unet_6_epochs.png" alt="Unconditional U-Net training loss" caption="Training loss for the unconditional U-Net." />

Results after 1 and 5 training epochs:

<ImageGrid>
<Figure src="/projects/cs180/proj5b/uncond/1_epoch_samples.png" alt="1 epoch samples (unconditional)" caption="Samples after 1 epoch (unconditional)." />
<Figure src="/projects/cs180/proj5b/uncond/5_epoch_samples.png" alt="5 epoch samples (unconditional)" caption="Samples after 5 epochs (unconditional)." />
</ImageGrid>

#### 1.2.2 Out-of-Distribution Testing

I tested denoising with $\sigma \neq 0.5$.

<Figure src="/projects/cs180/proj5b/uncond/out_of_dist_samples.png" alt="Out-of-distribution samples" caption="Denoising performance for out-of-distribution $\sigma$ values." />

The denoiser generalizes to unseen noise levels reasonably well.

<SectionDivider />

<a id="diffusion" />
## Part 2: Training a Diffusion Model

---

<a id="time-cond" />
### 2.1 Adding Time Conditioning to U-Net

<Figure src="/projects/cs180/proj5b/backbones/conditional_arch.png" alt="Time-conditioned U-Net architecture" caption="Time-conditioned U-Net architecture." />

<Figure src="/projects/cs180/proj5b/backbones/fc_long.png" alt="Fully connected block (time embedding)" caption="Fully connected block for time embeddings." />

I used a hidden dimension of 64, batch size of 128, Adam optimizer with learning rate 0.001, and an exponential learning rate scheduler with $\gamma = 0.9$.

---

<a id="training-diffusion" />
### 2.2 Training the U-Net

Training followed this algorithm:

$$
\begin{aligned}
&\textbf{Training}\\
&\text{Precompute } \bar{\alpha}\\
&\textbf{repeat}\\
&\quad \mathbf{x}_0 \sim \text{clean image from training set}\\
&\quad t \sim \mathrm{Uniform}(\{1,\ldots,T\})\\
&\quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\mathbf{I})\\
&\quad \mathbf{x}_t \gets \sqrt{\bar{\alpha}_t}\,\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}\\
&\quad \hat{\boldsymbol{\epsilon}} \gets \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\\
&\quad \text{update } \theta \text{ to minimize } \lVert \boldsymbol{\epsilon}-\hat{\boldsymbol{\epsilon}}\rVert^2\\
&\textbf{until happy}
\end{aligned}
$$

<Figure src="/projects/cs180/proj5b/time_cond/training_loss.png" alt="Time-conditioned U-Net training loss" caption="Training loss for the time-conditioned U-Net (20 epochs)." />

---

<a id="sampling-diffusion" />
### 2.3 Sampling from the U-Net

After training, sampling followed this algorithm:

$$
\begin{aligned}
&\textbf{Sampling}\\
&\text{Precompute } \boldsymbol{\beta},\, \boldsymbol{\alpha},\, \bar{\boldsymbol{\alpha}}\\
&\mathbf{x}_T \sim \mathcal{N}(\mathbf{0},\mathbf{I})\\
&\textbf{for } t=T \text{ to } 1 \text{ step } -1\\
&\quad \mathbf{z} \sim \mathcal{N}(\mathbf{0},\mathbf{I}) \text{ if } t>1,\ \text{else } \mathbf{z} \gets \mathbf{0}\\
&\quad \hat{\mathbf{x}}_0 \gets \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}_\theta(\mathbf{x}_t,t)\right)\\
&\quad \mathbf{x}_{t-1} \gets \frac{\sqrt{\bar{\alpha}_{t-1}}\,\beta_t}{1-\bar{\alpha}_t}\,\hat{\mathbf{x}}_0 + \frac{\sqrt{\alpha_t}\,\bigl(1-\bar{\alpha}_{t-1}\bigr)}{1-\bar{\alpha}_t}\,\mathbf{x}_t + \sqrt{\beta_t}\,\mathbf{z}\\
&\textbf{end for}\\
&\textbf{return } \mathbf{x}_0
\end{aligned}
$$

Samples after 5 and 20 epochs of training:

<ImageGrid>
<Figure src="/projects/cs180/proj5b/time_cond/5_epoch_samples.png" alt="5 epoch samples (time-conditioned)" caption="Samples after 5 epochs (time-conditioned)." />
<Figure src="/projects/cs180/proj5b/time_cond/20_epoch_samples.png" alt="20 epoch samples (time-conditioned)" caption="Samples after 20 epochs (time-conditioned)." />
</ImageGrid>

---

<a id="class-cond" />
### 2.4 Adding Class-Conditioning to U-Net

Class-conditioned training followed this algorithm:

$$
\begin{aligned}
&\textbf{Class-Conditioned Training}\\
&\text{Precompute } \bar{\alpha}\\
&\textbf{repeat}\\
&\quad (\mathbf{x}_0, c) \sim \text{clean image and label from training set}\\
&\quad \text{make } c \text{ one-hot};\ \text{with probability } p_{\text{uncond}} \text{ set } c \gets \mathbf{0}\\
&\quad t \sim \mathrm{Uniform}(\{1,\ldots,T\})\\
&\quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\mathbf{I})\\
&\quad \mathbf{x}_t \gets \sqrt{\bar{\alpha}_t}\,\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}\\
&\quad \hat{\boldsymbol{\epsilon}} \gets \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, c)\\
&\quad \text{update } \theta \text{ to minimize } \lVert \boldsymbol{\epsilon}-\hat{\boldsymbol{\epsilon}}\rVert^2\\
&\textbf{until happy}
\end{aligned}
$$

<Figure src="/projects/cs180/proj5b/class_cond/training_loss.png" alt="Class-conditioned U-Net training loss" caption="Training loss for the class-conditioned U-Net (20 epochs)." />

---

<a id="class-sampling" />
### 2.5 Sampling from the Class-Conditioned U-Net

Sampling with classifier-free guidance:

$$
\begin{aligned}
&\textbf{Class-Conditioned Sampling}\\
&\text{input: one-hot } c,\ \text{guidance scale } \gamma\\
&\mathbf{x}_T \sim \mathcal{N}(\mathbf{0},\mathbf{I})\\
&\textbf{for } t=T \text{ to } 1 \text{ step } -1\\
&\quad \mathbf{z} \sim \mathcal{N}(\mathbf{0},\mathbf{I}) \text{ if } t>1,\ \text{else } \mathbf{z} \gets \mathbf{0}\\
&\quad \boldsymbol{\epsilon}_u \gets \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \mathbf{0})\\
&\quad \boldsymbol{\epsilon}_c \gets \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, c)\\
&\quad \boldsymbol{\epsilon} \gets \boldsymbol{\epsilon}_u + \gamma\bigl(\boldsymbol{\epsilon}_c - \boldsymbol{\epsilon}_u\bigr)\\
&\quad \hat{\mathbf{x}}_0 \gets \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}\right)\\
&\quad \mathbf{x}_{t-1} \gets \frac{\sqrt{\bar{\alpha}_{t-1}}\,\beta_t}{1-\bar{\alpha}_t}\,\hat{\mathbf{x}}_0 + \frac{\sqrt{\alpha_t}\,\bigl(1-\bar{\alpha}_{t-1}\bigr)}{1-\bar{\alpha}_t}\,\mathbf{x}_t + \sqrt{\beta_t}\,\mathbf{z}\\
&\textbf{end for}\\
&\textbf{return } \mathbf{x}_0
\end{aligned}
$$

Samples after 5 and 20 epochs:

<ImageGrid>
<Figure src="/projects/cs180/proj5b/class_cond/5_epoch_samples.png" alt="5 epoch samples (class-conditioned)" caption="Samples after 5 epochs (class-conditioned)." />
<Figure src="/projects/cs180/proj5b/class_cond/20_epoch_samples.png" alt="20 epoch samples (class-conditioned)" caption="Samples after 20 epochs (class-conditioned)." />
</ImageGrid>

Initial samples were poor. After inspection, I found missing normalization layers in the convolutional blocks. After fixing this bug and re-launching training:

<Figure src="/projects/cs180/proj5b/ddpm_samples_training.gif" alt="DDPM sampling results over training epochs." caption="DDPM sampling results over training epochs." />

<ImageGrid>
<Figure src="/projects/cs180/proj5b/ddpm_samples.mp4" alt="DDPM sampling animation from noise with the trained model" caption="DDPM sampling process." />
<Figure src="/projects/cs180/proj5b/ddpm_samples.png" alt="DDPM generated samples (grid view)" caption="DDPM sampling results." />
</ImageGrid>

<SectionDivider />

<a id="flow-matching" />
## Bonus: Flow-Matching

Flow-matching models the data generation process as an ordinary differential equation (ODE):

$$
\frac{d\mathbf{x}_t}{dt} = \mathbf{v}(\mathbf{x}_t, t)
$$

where $\mathbf{x}_t$ is a data point at time $t \in [0, 1]$, and $\mathbf{v}(\mathbf{x}_t, t)$ is the velocity field that moves data from the noise distribution at $t=0$ to the data distribution at $t=1$.

The conditional flow connects each data point $\mathbf{x}_1$ to a noise point $\mathbf{x}_0$ by a straight line:

$$
\mathbf{x}_t = t\mathbf{x}_1 + (1-t)\mathbf{x}_0
$$

The velocity along this path is:

$$
\mathbf{v}_t = \frac{d\mathbf{x}_t}{dt} = \mathbf{x}_1 - \mathbf{x}_0
$$

The model is trained to predict this velocity. The loss minimizes the difference between the predicted velocity and the true velocity of the straight-line paths:

$$
\mathcal{L} = \mathbb{E}_{p(\mathbf{x}_1), p(\mathbf{x}_0), t \sim \mathcal{U}[0, 1]} [||\mathbf{v}_\theta(\mathbf{x}_t, t) - (\mathbf{x}_1 - \mathbf{x}_0)||^2]
$$

During sampling, a random noise vector $\mathbf{x}_0 \sim p(\mathbf{x}_0)$ is integrated forward using the Euler method.

<ImageGrid>
<Figure src="/projects/cs180/proj5b/rf_samples.mp4" alt="Rectified Flow sampling animation from noise" caption="Rectified Flow sampling process." />
<Figure src="/projects/cs180/proj5b/rf_samples.png" alt="Rectified Flow generated samples (grid view)" caption="Rectified Flow sampling results." />
</ImageGrid>
