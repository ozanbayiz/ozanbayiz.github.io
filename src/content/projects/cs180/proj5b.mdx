<a id="part-2" />
## Part 1: Training a Single-Step Denoising U-Net

<a id="part-2-1" />
### 1.1 Implementing the U-Net

I implemented an unconditional U-Net with the architecture provided in the project spec.

<Figure src="/projects/cs180/proj5b/backbones/unconditional_arch.png" alt="Unconditional U-Net architecture" caption="Figure 1. Unconditional U-Net architecture." />
<Figure src="/projects/cs180/proj5b/backbones/atomic_ops_new.png" alt="Atomic operations block" caption="Figure 2. Blocks that compose the backbone." />

<a id="part-2-2" />
### 1.2 Using the U-Net to Train a Denoiser

Given a clean image, $x$, I noised it to get $z = x + \sigma \epsilon$, where $\epsilon \sim \mathcal{N}(0, 1)$, and $\sigma \in \{0.0, 0.2, 0.4, 0.6, 0.8, 1.0\}$.

<Figure src="/projects/cs180/proj5b/uncond/noising_process.png" alt="Noising process" caption="Figure 3. Forward noising process for constructing $(\mathbf{x}, \mathbf{z})$ pairs." />

Using this, I created a dataloader which produced batches of the form $(x, z)$ with $ \sigma = 0.5 $.

<Figure src="/projects/cs180/proj5b/uncond/noising_dataloader.png" alt="Noising dataloader" caption="Figure 4. Noising dataloader output for $\sigma = 0.5$." />

<a id="part-2-2-1" />
#### 1.2.1 Training

I trained the U-Net to predict the noise $\epsilon_{\sigma} = z - x$, and optimized it against the loss $\| \epsilon_{\sigma}  - \hat{\epsilon}\|^2 $

<Figure src="/projects/cs180/proj5b/uncond/uncond_unet_6_epochs.png" alt="Unconditional U-Net training loss" caption="Figure 5. Training loss for the unconditional U-Net." />

Here are my results sampling after 1 and 5 training epochs.

<ImageGrid>

<Figure src="/projects/cs180/proj5b/uncond/1_epoch_samples.png" alt="1 epoch samples (unconditional)" caption="Figure 6. Samples after 1 epoch of training (unconditional)." />

<Figure src="/projects/cs180/proj5b/uncond/5_epoch_samples.png" alt="5 epoch samples (unconditional)" caption="Figure 7. Samples after 5 epochs of training (unconditional)." />

</ImageGrid>
The samples look reasonable after just a few epochs.

<a id="part-2-2-2" />
#### 1.2.2 Out-of-Distribution Testing

Then I tried denoising images with $\sigma \neq 0.5$.

<Figure src="/projects/cs180/proj5b/uncond/out_of_dist_samples.png" alt="Out-of-distribution samples" caption="Figure 8. Denoising performance for out-of-distribution $\sigma$ values." />

The denoiser generalizes to unseen noise levels reasonably well.

---

<a id="part-3" />
## Part 2: Training a Diffusion Model

<a id="part-3-1" />
### 2.1 Adding Time Conditioning to U-Net

I followed the spec and implemented time conditioning.

<Figure src="/projects/cs180/proj5b/backbones/conditional_arch.png" alt="Time-conditioned U-Net architecture" caption="Figure 9. Time-conditioned U-Net architecture." />

<Figure src="/projects/cs180/proj5b/backbones/fc_long.png" alt="Fully connected block (time embedding)" caption="Figure 10. Fully connected block used for time embeddings." />

As recommended in the spec, I used a hidden dimension of 64 and a batch size of 128. 
For optimization, I used Adam with a learning rate of 0.001 and an exponential learning rate scheduler with $\gamma = 0.9$.

<a id="part-3-2" />
### 2.2 Training the U-Net

Training the Unconditional U-Net followed this algorithm:

$$
\begin{aligned}
&\textbf{Training}\\
&\text{Precompute } \bar{\alpha}\\
&\textbf{repeat}\\
&\quad \mathbf{x}_0 \sim \text{clean image from training set}\\
&\quad t \sim \mathrm{Uniform}(\{1,\ldots,T\})\\
&\quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\mathbf{I})\\
&\quad \mathbf{x}_t \gets \sqrt{\bar{\alpha}_t}\,\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}\\
&\quad \hat{\boldsymbol{\epsilon}} \gets \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\\
&\quad \text{update } \theta \text{ to minimize } \lVert \boldsymbol{\epsilon}-\hat{\boldsymbol{\epsilon}}\rVert^2\\
&\textbf{until happy}
\end{aligned}
$$

I plotted the training loss $\| \epsilon - \hat{\epsilon} \|^2 $ for the time-conditioned U-Net during 20 epochs.

<Figure src="/projects/cs180/proj5b/time_cond/training_loss.png" alt="Time-conditioned U-Net training loss" caption="Figure 11. Training loss for the time-conditioned U-Net (20 epochs)." />

<a id="part-3-3" />
### 2.3 Sampling from the U-Net

After training, sampling from the U-Net followed this algorithm:

$$
\begin{aligned}
&\textbf{Sampling}\\
&\text{Precompute } \boldsymbol{\beta},\, \boldsymbol{\alpha},\, \bar{\boldsymbol{\alpha}}\\
&\mathbf{x}_T \sim \mathcal{N}(\mathbf{0},\mathbf{I})\\
&\textbf{for } t=T \text{ to } 1 \text{ step } -1\\
&\quad \mathbf{z} \sim \mathcal{N}(\mathbf{0},\mathbf{I}) \text{ if } t>1,\ \text{else } \mathbf{z} \gets \mathbf{0}\\
&\quad \hat{\mathbf{x}}_0 \gets \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}_\theta(\mathbf{x}_t,t)\right)\\
&\quad \mathbf{x}_{t-1} \gets \frac{\sqrt{\bar{\alpha}_{t-1}}\,\beta_t}{1-\bar{\alpha}_t}\,\hat{\mathbf{x}}_0 + \frac{\sqrt{\alpha_t}\,\bigl(1-\bar{\alpha}_{t-1}\bigr)}{1-\bar{\alpha}_t}\,\mathbf{x}_t + \sqrt{\beta_t}\,\mathbf{z}\\
&\textbf{end for}\\
&\textbf{return } \mathbf{x}_0
\end{aligned}
$$

I sampled after 5 and 20 epochs of training.

<ImageGrid>
<Figure src="/projects/cs180/proj5b/time_cond/5_epoch_samples.png" alt="5 epoch samples (time-conditioned)" caption="Figure 12. Samples after 5 epochs (time-conditioned)." />
<Figure src="/projects/cs180/proj5b/time_cond/20_epoch_samples.png" alt="20 epoch samples (time-conditioned)" caption="Figure 13. Samples after 20 epochs (time-conditioned)." />
</ImageGrid>
<a id="part-3-4" />
### 2.4 Adding Class-Conditioning to U-Net

I implemented class conditioning as specified in the spec. I used the same hyperparameters as in part 2.2, and got the following training loss for 20 epochs.

Class-conditioned training followed this algorithm.

$$
\begin{aligned}
&\textbf{Class-Conditioned Training}\\
&\text{Precompute } \bar{\alpha}\\
&\textbf{repeat}\\
&\quad (\mathbf{x}_0, c) \sim \text{clean image and label from training set}\\
&\quad \text{make } c \text{ one-hot};\ \text{with probability } p_{\text{uncond}} \text{ set } c \gets \mathbf{0}\\
&\quad t \sim \mathrm{Uniform}(\{1,\ldots,T\})\\
&\quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0},\mathbf{I})\\
&\quad \mathbf{x}_t \gets \sqrt{\bar{\alpha}_t}\,\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}\\
&\quad \hat{\boldsymbol{\epsilon}} \gets \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, c)\\
&\quad \text{update } \theta \text{ to minimize } \lVert \boldsymbol{\epsilon}-\hat{\boldsymbol{\epsilon}}\rVert^2\\
&\textbf{until happy}
\end{aligned}
$$

Once again, I plotted the training loss $\| \epsilon - \hat{\epsilon} \|^2$

<Figure src="/projects/cs180/proj5b/class_cond/training_loss.png" alt="Class-conditioned U-Net training loss" caption="Figure 14. Training loss for the class-conditioned U-Net (20 epochs)." />

<a id="part-3-5" />
### 2.5 Sampling from the Class-Conditioned U-Net

After training, sampling from the class-conditioned U-Net followed this algorithm:

$$
\begin{aligned}
&\textbf{Class-Conditioned Sampling}\\
&\text{input: one-hot } c,\ \text{guidance scale } \gamma\\
&\mathbf{x}_T \sim \mathcal{N}(\mathbf{0},\mathbf{I})\\
&\textbf{for } t=T \text{ to } 1 \text{ step } -1\\
&\quad \mathbf{z} \sim \mathcal{N}(\mathbf{0},\mathbf{I}) \text{ if } t>1,\ \text{else } \mathbf{z} \gets \mathbf{0}\\
&\quad \boldsymbol{\epsilon}_u \gets \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \mathbf{0})\\
&\quad \boldsymbol{\epsilon}_c \gets \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, c)\\
&\quad \boldsymbol{\epsilon} \gets \boldsymbol{\epsilon}_u + \gamma\bigl(\boldsymbol{\epsilon}_c - \boldsymbol{\epsilon}_u\bigr)\\
&\quad \hat{\mathbf{x}}_0 \gets \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t}\,\boldsymbol{\epsilon}\right)\\
&\quad \mathbf{x}_{t-1} \gets \frac{\sqrt{\bar{\alpha}_{t-1}}\,\beta_t}{1-\bar{\alpha}_t}\,\hat{\mathbf{x}}_0 + \frac{\sqrt{\alpha_t}\,\bigl(1-\bar{\alpha}_{t-1}\bigr)}{1-\bar{\alpha}_t}\,\mathbf{x}_t + \sqrt{\beta_t}\,\mathbf{z}\\
&\textbf{end for}\\
&\textbf{return } \mathbf{x}_0
\end{aligned}
$$

I sampled after 5 and 20 epochs of training.

<ImageGrid>
<Figure src="/projects/cs180/proj5b/class_cond/5_epoch_samples.png" alt="5 epoch samples (class-conditioned)" caption="Figure 15. Samples after 5 epochs (class-conditioned)." />
<Figure src="/projects/cs180/proj5b/class_cond/20_epoch_samples.png" alt="20 epoch samples (class-conditioned)" caption="Figure 16. Samples after 20 epochs (class-conditioned)." />
</ImageGrid>

Something was wrong. My handwriting is pretty bad too, but like, come on man.

After closer inspection, I noticed that I was missing normalization layers in my convolutional blocks. So I fixed this bug and re-launched training.


<Figure src="/projects/cs180/proj5b/ddpm_samples_training.gif" alt="DDPM sampling results over training epochs." caption="Figure 17. DDPM sampling results over training epochs." />

The samples were cleaner this time around. Normalization layers matter.

<ImageGrid>
<Figure src="/projects/cs180/proj5b/ddpm_samples.mp4" alt="DDPM sampling animation from noise with the trained model" caption="Figure 18. DDPM sampling process." />
<Figure src="/projects/cs180/proj5b/ddpm_samples.png" alt="DDPM generated samples (grid view)" caption="Figure 19.  DDPM sampling results." />
</ImageGrid>


<a id="appendix-rf" />
## Bonus: Flow-Matching

Flow-matching models the data generation process as an ordinary differential equation (ODE):

$$
\frac{d\mathbf{x}_t}{dt} = \mathbf{v}(\mathbf{x}_t, t)
$$

where $\mathbf{x}_t$ is a data point at time $t \in [0, 1]$, and $\mathbf{v}(\mathbf{x}_t, t)$ is the velocity vector field that moves the data from the noise distribution at $t=0$ to the data distribution at $t=1$. 

The key idea of flow-matching is to define a conditional probability path, or "flow," from noise to data. 
A common choice is the conditional flow, where each data point $\mathbf{x}_1$ is connected to a noise point $\mathbf{x}_0$ by a straight line.

$$
\mathbf{x}_t = t\mathbf{x}_1 + (1-t)\mathbf{x}_0
$$

The velocity vector for this path is simply the difference between the data and noise points:

$$
\mathbf{v}_t = \frac{d\mathbf{x}_t}{dt} = \mathbf{x}_1 - \mathbf{x}_0
$$

The model, which we call a neural ODE, is trained to predict this velocity vector. 
The loss function minimizes the difference between the predicted velocity and the true velocity of the straight-line paths, averaged over all data points and times:

$$
\mathcal{L} = \mathbb{E}_{p(\mathbf{x}_1), p(\mathbf{x}_0), t \sim \mathcal{U}[0, 1]} [||\mathbf{v}_\theta(\mathbf{x}_t, t) - (\mathbf{x}_1 - \mathbf{x}_0)||^2]
$$

During sampling, you start with a random noise vector $\mathbf{x}_0 \sim p(\mathbf{x}_0)$ and numerically solve the ODE to get the final data point $\mathbf{x}_1$.
I opted with the Euler method for ease of implementation.

<ImageGrid>
<Figure src="/projects/cs180/proj5b/rf_samples.mp4" alt="Rectified Flow sampling animation from noise" caption="Figure 20. Rectified Flow sampling process." />
<Figure src="/projects/cs180/proj5b/rf_samples.png" alt="Rectified Flow generated samples (grid view)" caption="Figure 21. Rectified Flow sampling results." />
</ImageGrid>
