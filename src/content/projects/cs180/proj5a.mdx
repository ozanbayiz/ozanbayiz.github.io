<a id="part-0" />
## Part 0: Setup

The seed I chose is 80808. Here are the images I generated for this part with 20 inference steps:

<Figure src="/projects/cs180/proj5a/original_generated_imgs.png" alt="original generated imgs" caption="Samples with 20 inference steps (seed 80808)." />

The quality of the images seems pretty consistent across different text prompts.

Here is the result of picking different numbers of inference steps:

<Figure src="/projects/cs180/proj5a/comparing_different_num_inference_steps.png" alt="comparing steps" caption="Comparison across different numbers of inference steps." />

---

<a id="part-1" />
## Part 1: Sampling Loops

<a id="part-1-1" />
### 1.1 Implementing the Forward Process

I implemented the forward process according to the spec.

<Figure src="/projects/cs180/proj5a/forward_noising_camp.png" alt="forward noising camp" caption="Forward noising at increasing time steps." />

<a id="part-1-2" />
### 1.2 Classical Denoising

I tried to denoise the noised image with gaussian filtering. This worked about as well as expected.

<Figure src="/projects/cs180/proj5a/filtered_noise_levels.png" alt="filtered noise levels" caption="Gaussian denoising across noise levels." />

<a id="part-1-3" />
### 1.3 One-Step Denoising

I implemented the one-step denoising process. I noticed that single-step denoising on an image with a lot of noise changed the content of the image.

<Figure src="/projects/cs180/proj5a/single_step_denoising.png" alt="single step denoising" caption="One-step denoising results." />

<a id="part-1-4" />
### 1.4 Iterative Denoising

I implemented the iterative denoising process according to the spec. Here's a gif created from every frame of the denoising process.

<Figure src="/projects/cs180/proj5a/iterative_denoise.gif" alt="iterative denoise gif" caption="Iterative denoising process (animation)." />

And here's a comparison of the iterative denoising and other denoising methods:

<Figure src="/projects/cs180/proj5a/iter_denoise_comparisons.png" alt="iter denoise comparisons" caption="Iterative vs single-step vs Gaussian denoising comparison." />

<a id="part-1-5" />
### 1.5 Diffusion Model Sampling

By applying the iterative denoising steps that I defined in part 1.4 to pure noise, I was able to generate new images.

 
<ImageGrid>
![gen 1](/projects/cs180/proj5a/generated_imgs/1.png)
![gen 2](/projects/cs180/proj5a/generated_imgs/2.png)
![gen 3](/projects/cs180/proj5a/generated_imgs/3.png)
![gen 4](/projects/cs180/proj5a/generated_imgs/4.png)
![gen 5](/projects/cs180/proj5a/generated_imgs/5.png)
</ImageGrid>
 

<a id="part-1-6" />
### 1.6 Classifier-Free Guidance (CFG)

I implemented classifier-free guidance according to the spec.

 
<ImageGrid>
![cfg 0](/projects/cs180/proj5a/generated_cfg/0.png)
![cfg 1](/projects/cs180/proj5a/generated_cfg/1.png)
![cfg 2](/projects/cs180/proj5a/generated_cfg/2.png)
![cfg 3](/projects/cs180/proj5a/generated_cfg/3.png)
![cfg 4](/projects/cs180/proj5a/generated_cfg/4.png)
</ImageGrid>
 

<a id="part-1-7" />
### 1.7 Image-to-image Translation

I applied various amounts of noise to the test image to get the following results.

<Figure src="/projects/cs180/proj5a/1.7.0/test_img_altogether.png" alt="i2i altogether" caption="Image-to-image results vs noise strength (test image)." />

Here is the result of applying different amounts of noise to cheems.

<Figure src="/projects/cs180/proj5a/1.7.0/cheems_altogether.png" alt="cheems altogether" caption="Image-to-image results vs noise strength (cheems)." />

And here are the results for a picture I found on a [cool wikipedia page about ecdysis](https://en.wikipedia.org/wiki/Ecdysis).

<Figure src="/projects/cs180/proj5a/1.7.0/spider_altogether.png" alt="spider altogether" caption="Image-to-image results vs noise strength (spider)." />

<a id="part-1-7-1" />
#### 1.7.1 Editing Hand-Drawn and Web Images

The image I chose from the web is nyan cat.

<Figure src="/projects/cs180/proj5a/1.7.1/nyan_cat.png" alt="nyan cat" caption="Web image used for editing (Nyan Cat)." />

Here are the results of editing two images I drew.

<Figure src="/projects/cs180/proj5a/1.7.1/moon_sketch.png" alt="moon sketch" caption="Hand-drawn sketch: moon." />

<Figure src="/projects/cs180/proj5a/1.7.1/drawn_cat.png" alt="drawn cat" caption="Hand-drawn sketch: cat." />

<a id="part-1-7-2" />
#### 1.7.2 Inpainting

Here is the inpainted image of the Campanile.

<Figure src="/projects/cs180/proj5a/1.7.2/camp_inpainted.png" alt="camp inpainted" caption="Inpainting result: Campanile." />

I wondered how the diffusion model would fill in nyan cat's rainbow trail. I was sort of disappointed.

<Figure src="/projects/cs180/proj5a/1.7.2/nyan_cat_inpainted.png" alt="nyan cat inpainted" caption="Inpainting result: Nyan Cat." />

I also wondered how the diffusion model would fill in Aphex Twin's face; I was similarly disappointed.

<Figure src="/projects/cs180/proj5a/1.7.2/aphex_inpainted.png" alt="aphex inpainted" caption="Inpainting result: Aphex Twin." />

<a id="part-1-7-3" />
#### 1.7.3 Text-Conditional Image-to-image Translation

I just turned everything into a rocket.

<Figure src="/projects/cs180/proj5a/1.7.3/rocket_camp.png" alt="rocket camp" caption="Text-conditional translation: campfire to rocket." />
<Figure src="/projects/cs180/proj5a/1.7.3/rocket_nyan_cat.png" alt="rocket nyan" caption="Text-conditional translation: Nyan Cat to rocket." />
<Figure src="/projects/cs180/proj5a/1.7.3/rocket_cheems.png" alt="rocket cheems" caption="Text-conditional translation: cheems to rocket." />

<a id="part-1-8" />
### 1.8 Visual Anagrams

I was pleasantly surprised by how well this part worked. Here is my result for 
<i>A visual anagram where on one orientation "an oil painting of people around a campfire" is displayed and, when flipped, "an oil painting of an old man" is displayed.</i>

<Figure src="/projects/cs180/proj5a/1.8/old_man_campfire.png" alt="old man campfire" caption="Visual anagram: campfire vs old man." />

Here are my other results:

<Figure src="/projects/cs180/proj5a/1.8/skull_coast.png" alt="skull coast" caption="Visual anagram result: skull/coast." />
<Figure src="/projects/cs180/proj5a/1.8/dog_man_hhat.png" alt="dog man hhat" caption="Visual anagram result." />

<a id="part-1-9" />
### 1.9 Hybrid Images

Although I got odd results, I'm pretty sure I implemented this part correctly. To justify my odd results, I'll explain my steps.

1. Given my two prompts, $p_1$ and $ p_2 $ I found noise estimates $\epsilon_1(x_t, t, p_1) $ and  $ \epsilon_2(x_t, t, p_2)$.
2. I convolved $\epsilon_1$ and $\epsilon_2 $ with a Gaussian kernel $(k=33, \sigma = 2$, as recommended) to get the low-frequency components, $\epsilon_1^{(LF)}$ and $\epsilon_2^{(LF)}$.
3. I got the high-frequency component $\epsilon_2^{(HF)} = \epsilon_2 - \epsilon_2^{(LF)}$.
4. I added $\epsilon_1^{(HF)}$ and $\epsilon_2^{(HF)}$ together to get the hybrid noise estimate $\epsilon_{\text{hybrid}}$.
5. I used $ \epsilon_{\text{hybrid}} $ to denoise the image at time $t$.

here is the result I got for the skull and waterfall:

<Figure src="/projects/cs180/proj5a/1.9/skull_waterfall.png" alt="skull waterfall" caption="Hybrid images: skull/waterfall." />

here are the other results I got:

 

<Figure src="/projects/cs180/proj5a/1.9/rocket_man_hat.png" alt="rocket man hat" caption="Hybrid images: rocket/man hat." />
<Figure src="/projects/cs180/proj5a/1.9/hipster_barista_dog.png" alt="hipster barista dog" caption="Hybrid images: hipster barista dog." />
<Figure src="/projects/cs180/proj5a/1.9/old_man_snow.png" alt="old man snow" caption="Hybrid images: old man in snow." />

 

---


