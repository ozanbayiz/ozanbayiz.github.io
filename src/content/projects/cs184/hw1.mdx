---
title: "Rasterizer"
shortTitle: "Rasterizer"
description: "Software triangle rasterizer: supersampling, barycentrics, bilinear + trilinear texture filtering, mipmaps."
thumbnail: "/projects/cs184/hw1/competition.png"
heroImage: "/projects/cs184/hw1/competition.png"
gitUrl: "https://github.com/ozanbayiz/hw1-rasterizer-i-see-things-1"
date: "2026-02-14"
---

<a id="overview" />
## Overview

I built a software triangle rasterizer from scratch. The pipeline starts with single-color pixels, then adds supersampling for antialiasing, barycentric interpolation for per-vertex attributes, and texture mapping with both pixel and level sampling. By the end it supports full bilinear and trilinear mipmap filtering.

The core idea is sampling: where we sample, how many samples per pixel, and at what resolution. Each choice trades quality for cost. Aliasing appears at every stage of the pipeline, and each fix is a form of low-pass filtering.
What I found most interesting is how simple primitives compose; bounding-box iteration, weighted averages, and logarithmic level selection each solve a narrow problem, but together they form a coherent rendering pipeline. It's pretty neat to see how such an expressive system is built from such simple pieces.

<SectionDivider />

<a id="task-1" />
## Task 1: Drawing Single-Color Triangles

I implemented triangle rasterization using a bounding-box approach with edge functions. The algorithm works in four steps:

1. **Bounding box.** Compute the axis-aligned bounding box of the three vertices: `x_min`, `x_max`, `y_min`, `y_max`. Clamp to the framebuffer so we never access out-of-bounds memory.

2. **Edge function evaluation.** For each pixel center in the bounding box, evaluate three edge functions. For edge $i$ connecting vertex $i$ to vertex $i{+}1$:

$$
e_i(\mathbf{p}) = (x_{i+1} - x_i)(p_y - y_i) - (y_{i+1} - y_i)(p_x - x_i)
$$

3. **Winding normalization.** Before the loop, I compute the signed area $\text{cross}_z = (x_1{-}x_0)(y_2{-}y_0) - (y_1{-}y_0)(x_2{-}x_0)$. If it is negative (clockwise winding), I swap vertices 1 and 2 to guarantee counter-clockwise order. The inner loop then only needs to test $e_i \ge 0$.

4. **Top-Left Rule.** Adjacent triangles share edges. A sample exactly on a shared edge must belong to exactly one triangle to avoid gaps or double-drawing. The top-left rule: include a sample on an edge ($e_i = 0$) only when that edge is either (a) horizontal and pointing right, or (b) non-horizontal and pointing up. All other edges exclude their boundary samples. Implementation:

```cpp
bool in_i = (e_i > 0) || (e_i == 0 && is_top_left(edge_i));
```


### Why the bounding box is enough
We iterate only over pixel centers inside the axis-aligned bounding box of the triangle. Any algorithm must at least check every such sample to know if it is inside. We do exactly that, and no more.

### Results
<Figure src="/projects/cs184/hw1/task1_test4.png" alt="test4.svg with pixel inspector on thin triangle corner" caption="1 sample/pixel." />

### Extra Credit: Rasterization Optimizations

I added a three-tier optimization pipeline for `rasterize_triangle` (toggle with `O`). Each tier stacks on the last:

| Tier | Optimization | Idea |
| --- | --- | --- |
| 1 | Incremental edge evaluation | Express each edge function as $E_i(p) = A_i p_x + B_i p_y + C_i$. Step by adding precomputed coefficients $A_i$ (horizontal) and $B_i$ (vertical). Reduces the inner loop from 6 multiplies to 3 additions per edge. |
| 2 | Scanline early exit | Because triangles are convex, once we enter and then leave the triangle on a scanline, no further pixels on that row can be inside. Break early, avoiding work on the trailing portion of each row. |
| 3 | Hierarchical tiled accept/reject | Divide the bounding box into 8×8 tiles. For each tile, evaluate all three edge functions at the four corners. If any edge is negative at all four corners, trivial reject (skip tile). If all edges are positive at all four corners, trivial accept (fill all subsamples without per-sample testing). Otherwise, fall back to per-pixel testing. |

*Timing comparison (mean over 10 iterations on `basic/test3.svg`, 800×600, sr=16):*

| Configuration | Mean (ms) | Speedup |
| --- | --- | --- |
| Baseline | 172 | 1.00× |
| +Incremental | 151 | 1.14× |
| +Incr + Early Exit | 152 | 1.13× |
| +Incr + Early + Tiled | 89 | **1.93×** |

Tiling gives the biggest speedup. Trivial accept fills whole tiles without per-sample tests; trivial reject skips empty tiles entirely. Incremental edge eval cuts per-sample work. Scanline early exit helps on narrow triangles, but has less impact on large screen-filling geometry.

<SectionDivider />

<a id="task-2" />
## Task 2: Antialiasing by Supersampling

Supersampling antialiases triangle edges by testing $N$ points per pixel instead of one, then averaging them at resolve time. More subsamples yield smoother edges; the tradeoff is $\times N$ more work and memory.

### Algorithm and Data Structures

The supersample buffer stores `width × height × sample_rate` colors. For pixel $(x, y)$, its $N$ subsamples are stored consecutively, ordered by subsample index $s$.

Within each pixel, subsamples lie on a uniform $\sqrt{N} \times \sqrt{N}$ grid. Subsample $s$ has offset:

$$
\left(\frac{s \bmod \sqrt{N} + 0.5}{\sqrt{N}},\;\; \frac{\lfloor s / \sqrt{N} \rfloor + 0.5}{\sqrt{N}}\right)
$$

Each subsample gets its own edge test and color. At resolve time, `resolve_to_framebuffer()` averages all $N$ subsamples per pixel to produce the final output.

### Pipeline Modifications

- Resizing the framebuffer or sample rate resizes the supersample buffer to match.
- Points and lines write the same color to all $N$ subsamples of each pixel, so they stay sharp regardless of sample rate.
- Clearing fills the buffer with white.

### Why Supersampling Helps

With one sample per pixel, the result is binary: inside or not, fully colored or fully white. With $N$ subsamples we get $N{+}1$ coverage levels instead of 2, giving edges and thin features room to smooth.

### Results

Screenshots of `basic/test4.svg` with default viewing parameters, pixel inspector on the thin triangle corner, sample rates 1, 4, and 16:

<ImageGrid>
<Figure src="/projects/cs184/hw1/task2_sr1.png" alt="1 sample per pixel, basic/test4.svg" caption="1 sample/pixel: harsh discontinuity; binary coverage." />
<Figure src="/projects/cs184/hw1/task2_sr4.png" alt="4 samples per pixel" caption="4 samples/pixel: edges soften with partial coverage." />
<Figure src="/projects/cs184/hw1/task2_sr9.png" alt="9 samples per pixel" caption="9 samples/pixel: finer coverage gradient." />
<Figure src="/projects/cs184/hw1/task2_sr16.png" alt="16 samples per pixel" caption="16 samples/pixel: reasonably smooth gradient" />
</ImageGrid>

At 1× the triangle tip staircases; each pixel is either full magenta or full white. At 4× the edges soften: pixels along the boundary get partial coverage (1/4, 2/4, or 3/4), producing intermediate pink shades. At 16× we get 17 coverage levels and a much smoother gradient.

### Extra Credit: RGSS (Rotated Grid Super-Sampling)

I implemented RGSS as an alternative 4× sample pattern (toggle with `A` at runtime). RGSS places samples on a grid rotated ~26.6° from the pixel axes, with offsets:

```
(0.375, 0.125), (0.875, 0.375), (0.125, 0.625), (0.625, 0.875)
```

The rotation staggers samples so no two share the same row or column. A near-horizontal edge then crosses them one at a time as we move down the pixel, giving 4 distinct coverage levels (0/4, 1/4, 2/4, 3/4 covered). The standard 2×2 grid has two samples on the same $y$. A near-horizontal edge can cross both at once, so the pixel flips from fully covered to fully uncovered with no in-between. RGSS avoids that.

<ImageGrid>
<Figure src="/projects/cs184/hw1/ec_task2_grid.png" alt="4x grid sampling" caption="4× grid: shared columns cause pixel-wide discontinuity on near-vertical edges." />
<Figure src="/projects/cs184/hw1/ec_task2_rgss.png" alt="4x RGSS sampling" caption="4× RGSS: unique row/column per sample; smoother near-vertical edges." />
</ImageGrid>

<SectionDivider />

<a id="task-3" />
## Task 3: Transforms

I wanted cubeman to lay flat on the floor like how I do sometimes. The result is a black figure in an **X** pose built entirely from translated, rotated, and scaled rectangles:

- `translate(±90, ∓90)` on each arm positions the shoulder, then `rotate(±45)` aligns the segments along the diagonal.
- `translate(±90, 90)` on each leg with `rotate(∓45)` mirrors the arms below the torso.
- Each limb has two rectangular segments (upper + lower), `scale`d to thin rectangles and stacked along the rotated axis for a jointed look.
- The head uses `translate(0, −100)` and `rotate(45)` to produce a diamond shape above the torso.

<Figure src="/projects/cs184/hw1/task3_robot.png" alt="Black robot in X pose" caption="Custom robot (my_robot.svg): translate, rotate, scale." />

### Extra Credit: Viewport Rotation

I added viewport rotation via two controls: `R` / `Shift+R` for discrete ±15° steps, and **Shift+drag** for continuous rotation.

The implementation inserts a rotation matrix between the centering translation and the NDC scale:

$$
M_{\text{svg}\to\text{ndc}} = S \cdot R(\theta) \cdot T(-c_x, -c_y)
$$

$T$ centers the view, $R(\theta)$ rotates by the current angle, $S$ scales to NDC. I apply $R(-\theta)$ to the drag delta so panning feels correct regardless of the current rotation. `Space` resets everything.

<ImageGrid>
<Figure src="/projects/cs184/hw1/ec_task3_rotate_30.png" alt="Viewport rotated 30 degrees" caption="Viewport rotated +30°." />
<Figure src="/projects/cs184/hw1/ec_task3_rotate_neg45.png" alt="Viewport rotated -45 degrees" caption="Viewport rotated −45°." />
</ImageGrid>

<SectionDivider />

<a id="task-4" />
## Task 4: Barycentric Coordinates

Barycentric coordinates let us interpolate per-vertex attributes (color, UVs, normals) across the triangle. A point $\mathbf{p}$ inside the triangle is a weighted sum of the three vertices:

$$
\mathbf{p} = \alpha \, \mathbf{V}_0 + \beta \, \mathbf{V}_1 + \gamma \, \mathbf{V}_2, \quad \alpha + \beta + \gamma = 1
$$

Each weight $\alpha$, $\beta$, $\gamma$ is the area of a sub-triangle (with $\mathbf{p}$ and two vertices) divided by the full triangle area. $\alpha$ measures how close $\mathbf{p}$ is to $\mathbf{V}_0$: at $\mathbf{V}_0$ we have $\alpha{=}1$; at the centroid, $\alpha{=}\beta{=}\gamma{=}\tfrac{1}{3}$. A point is inside the triangle when all three weights are $\ge 0$.

We use the same weights to interpolate any per-vertex attribute (color, UVs, normals). The RGB triangle below assigns red to vertex 0, green to vertex 1, and blue to vertex 2. Interior pixels blend all three according to these weights.

<ImageGrid>
<Figure src="/projects/cs184/hw1/task4_bary_rgb.png" alt="Single triangle with red, green, and blue vertices" caption="RGB triangle: barycentric blends at vertices." />
<Figure src="/projects/cs184/hw1/task4_test7.png" alt="basic/test7.svg at sample rate 1" caption="basic/test7.svg (sr=1): color wheel from barycentric-interpolated triangles." />
</ImageGrid>

<SectionDivider />

<a id="task-5" />
## Task 5: Pixel Sampling for Texture Mapping

Texture mapping maps screen samples to texture coordinates $(u, v)$ via barycentric interpolation. The sample usually lands between texel centers, so we need a strategy to pick a color from the texture.

- **Nearest** (`P_NEAREST`): snap to the closest texel by flooring the continuous coordinates to integer texel indices. Fast, with blocky, pixelated artifacts when the texture is magnified.
- **Bilinear** (`P_LINEAR`): grab the four surrounding texel centers, compute fractional $s$ and $t$, blend:

$$
C = (1{-}s)(1{-}t)\,C_{00} + s(1{-}t)\,C_{10} + (1{-}s)\,t\,C_{01} + s\,t\,C_{11}
$$

4 texel fetches and 3 lerps per sample.

I took screenshots from the `svg/texmap/` directory with the pixel inspector on a magnified region where bilinear clearly defeats nearest. Four combinations:

<ImageGrid>
<Figure src="/projects/cs184/hw1/task5_nearest_1x.png" alt="Nearest, 1 sample per pixel" caption="P_NEAREST, 1×: blocky when magnified." />
<Figure src="/projects/cs184/hw1/task5_bilinear_1x.png" alt="Bilinear, 1 sample per pixel" caption="P_LINEAR, 1×: smooth texel blending." />
<Figure src="/projects/cs184/hw1/task5_nearest_16x.png" alt="Nearest, 16 samples per pixel" caption="P_NEAREST, 16×: blockiness reduced, not eliminated." />
<Figure src="/projects/cs184/hw1/task5_bilinear_16x.png" alt="Bilinear, 16 samples per pixel" caption="P_LINEAR, 16×: best quality in magnified regions." />
</ImageGrid>

**When the difference matters most.** During magnification (one pixel covers less than one texel), nearest snaps every sample to the same texel center, giving hard block edges. Bilinear blends the four surrounding texels, so colors change smoothly. At 1× supersampling the difference is obvious; at 16×, supersampling averages many lookups per pixel and partly masks nearest's blockiness.

**When both struggle.** During minification (one pixel covers many texels), both methods read from too small a neighborhood. The pixel's true footprint spans many texels, so both alias. Mipmaps fix that by pre-filtering at lower resolutions.

<SectionDivider />

<a id="task-6" />
## Task 6: Level Sampling with Mipmaps

When a screen pixel covers many texels (e.g., a textured floor in the distance), sampling a single texel aliases: we get Moiré patterns and sparkle. Mipmaps solve this by pre-filtering the texture into a pyramid of progressively lower resolutions (level 0 = full res, level 1 = half, etc.). Level sampling chooses which resolution to use.

### Implementation

We need to know how many texels a screen pixel spans. That depends on how fast $(u, v)$ change as we move one pixel right or one pixel down. For each sample at $(px, py)$, I compute the barycentrics at $(px{+}1, py)$ and $(px, py{+}1)$ to get the UV derivatives $\partial(u,v)/\partial x$ and $\partial(u,v)/\partial y$. The mip level is:

$$
D = \log_2 \max\!\left(\left\lVert \frac{\partial(u,v)}{\partial x} \cdot (w, h) \right\rVert,\;\; \left\lVert \frac{\partial(u,v)}{\partial y} \cdot (w, h) \right\rVert\right)
$$

where $(w, h)$ are the full-resolution texture dimensions. Then:

- **`L_ZERO`**: Always sample from level 0. No minification handling, so it aliases when zoomed out. Fastest option.
- **`L_NEAREST`**: Round $D$ to the nearest integer and sample from that mip level. Reduces aliasing; can produce visible seams at level transitions.
- **`L_LINEAR`**: Sample from $\lfloor D \rfloor$ and $\lfloor D \rfloor {+} 1$, blend by the fractional part of $D$. Two texture lookups. With `P_LINEAR` → trilinear. With `P_NEAREST` → linear in level only.

### Tradeoffs

| Technique | Speed | Memory | Anti-aliasing power |
| --- | --- | --- | --- |
| Supersampling ($N\times$) | Slow ($\times N$ work) | Large ($\times N$ buffer) | Effective for all edge types |
| Bilinear pixel sampling | Moderate (~4 texel fetches) | None extra | Smooths magnification only |
| Mip-level sampling | Fast (constant overhead) | +33% (mip pyramid) | Smooths minification |

Supersampling works everywhere but costs $\times N$ in work and memory. Bilinear is cheap and fixes magnification only; it has no effect on minification. Mipmaps target minification specifically and add ~33% memory for the pyramid.

### Results with Custom Texture

I used a 1024×1024 zone plate (Fresnel pattern) as my custom texture (`img/custom.png`). A zone plate has radially increasing spatial frequency: low-frequency rings near the center and progressively higher-frequency rings toward the edges. That makes it a good test target: minification aliasing (Moiré patterns) shows up naturally in the high-frequency periphery, while the smooth center reveals magnification quality. Four combinations:

<ImageGrid>
<Figure src="/projects/cs184/hw1/task6_l0_pn.png" alt="L_ZERO + P_NEAREST" caption="L_ZERO + P_NEAREST: worst case; severe aliasing and Moiré." />
<Figure src="/projects/cs184/hw1/task6_l0_pl.png" alt="L_ZERO + P_LINEAR" caption="L_ZERO + P_LINEAR: smooth magnification; minification aliases." />
<Figure src="/projects/cs184/hw1/task6_ln_pn.png" alt="L_NEAREST + P_NEAREST" caption="L_NEAREST + P_NEAREST: mipmaps help minification; magnification blocky." />
<Figure src="/projects/cs184/hw1/task6_ln_pl.png" alt="L_NEAREST + P_LINEAR" caption="L_NEAREST + P_LINEAR: best; mipmaps + bilinear." />
</ImageGrid>

### Extra Credit: Anisotropic Filtering

I implemented anisotropic filtering (toggle with `L` to cycle to "anisotropic" mode).

**The problem.** A screen pixel often projects to an elongated rectangle in texture space (e.g., a floor receding into the distance). Isotropic mipmaps pick one blur level based on the larger derivative. That over-blurs in the narrow direction: we lose detail along the long axis.

**The fix: sample along the long axis.** Anisotropic filtering treats the pixel's texture-space footprint as having a short axis and a long axis:

1. Compute how far $(u,v)$ move per screen pixel in $x$ and $y$; these give the two axes of the footprint in texel space.
2. The **shorter** axis sets the mip level (resolution for the narrow direction).
3. The **longer** axis sets how many samples we need: $N = \lceil \text{long} / \text{short} \rceil$, clamped to 8.
4. Take $N$ evenly-spaced trilinear samples along the long axis and average them.

When the footprint is nearly square, $N{=}1$ and we get a single trilinear sample. When it is elongated, multiple samples along the long axis preserve detail that isotropic filtering would blur.

<ImageGrid>
<Figure src="/projects/cs184/hw1/ec_task6_trilinear.png" alt="Trilinear filtering over-blurs along minor axis" caption="Trilinear: over-blurs along short axis for elongated footprints." />
<Figure src="/projects/cs184/hw1/ec_task6_aniso.png" alt="Anisotropic filtering preserves detail" caption="Anisotropic: preserves detail along elongated direction." />
</ImageGrid>

<SectionDivider />

<a id="art-competition" />
## Extra Credit: Art Competition

<Figure src="/projects/cs184/hw1/competition.png" alt="Sandwich" caption="Sandwich" />

I generated this 800×800 image with a Python script (`src/gen_competition.py`) seeded with `random.seed(8)`. The script emits procedural SVG as a stream of `colortri` elements that the rasterizer draws at 16× supersampling.

The script draws ~25k triangles across 17 layers. All layers share a cyclic palette (indigo, fuchsia, lime, white, silver) with per-vertex Gaussian noise for texture. The script builds the composition from many procedural primitives: radial spider-web threads and catch rings, concentric interference rings, arc-shaped aurora bands, octagram stars with girih fills, shattered ring shards, spiral particle fields, diffusion random walks with recursive branching, fractal tree branches, a jittered Sierpinski mandala, dust micro-triangles, and articulated spider legs. Each primitive uses polar coordinates and controlled randomness to create radial structure radiating from the center.