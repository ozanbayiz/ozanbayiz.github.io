import fs from 'node:fs'
import path from 'node:path'
import matter from 'gray-matter'

const ROOT = path.resolve(import.meta.dirname, '..')
const CONTENT_DIR = path.join(ROOT, 'src/content/projects')
const PROJECTS_OUT = path.join(ROOT, 'src/features/projects/data/projects.generated.ts')
const REGISTRY_OUT = path.join(ROOT, 'src/content/projects/registry.generated.ts')

const COURSE_COLLECTIONS = new Set(['cs180', 'cs184', 'cs185', 'cs280'])
const VALID_COLLECTIONS = new Set(['cs180', 'cs184', 'cs185', 'cs280', 'personal', 'misc-academic'])

type Frontmatter = {
    title: string
    description: string
    gitUrl: string
    thumbnail: string
    heroImage?: string
    heroAlt?: string
    shortTitle?: string
    date?: string
    authors?: string[]
    pdfUrl?: string
    demoUrl?: string
    featured?: boolean
    hideHero?: boolean
    slug?: string
}

const REQUIRED: (keyof Frontmatter)[] = ['title', 'description', 'gitUrl', 'thumbnail']

function collectMdxFiles(dir: string): string[] {
    const entries = fs.readdirSync(dir, { withFileTypes: true, recursive: true })
    return entries
        .filter(e => e.isFile() && e.name.endsWith('.mdx'))
        .map(e => path.join(e.parentPath ?? e.path, e.name))
}

function deriveSlug(collection: string, filename: string): string {
    if (COURSE_COLLECTIONS.has(collection)) return `${collection}-${filename}`
    return filename
}

function main() {
    const mdxFiles = collectMdxFiles(CONTENT_DIR)
    const projects: Array<{
        collection: string
        slug: string
        canonicalKey: string
        importPath: string
        fm: Frontmatter
    }> = []

    let hasError = false

    for (const filepath of mdxFiles) {
        const rel = path.relative(CONTENT_DIR, filepath)
        const parts = rel.split(path.sep)
        if (parts.length !== 2) {
            console.warn(`  skip: ${rel} (not in a collection subdirectory)`)
            continue
        }

        const [collection, file] = parts
        const filename = file.replace(/\.mdx$/, '')

        if (!VALID_COLLECTIONS.has(collection)) {
            console.warn(`  skip: ${rel} (unknown collection "${collection}")`)
            continue
        }

        const raw = fs.readFileSync(filepath, 'utf-8')
        const { data } = matter(raw)
        const fm = data as Partial<Frontmatter>

        for (const key of REQUIRED) {
            if (!fm[key]) {
                console.error(`  ERROR: ${rel} missing required field "${key}"`)
                hasError = true
            }
        }

        if (hasError) continue

        const slug = fm.slug ?? deriveSlug(collection, filename)
        const canonicalKey = `${collection}/${filename}`
        const importPath = `./${collection}/${file}`

        projects.push({
            collection,
            slug,
            canonicalKey,
            importPath,
            fm: fm as Frontmatter
        })
    }

    if (hasError) {
        console.error('\nFrontmatter validation failed. Fix errors above.')
        process.exit(1)
    }

    projects.sort((a, b) => {
        const da = a.fm.date ? Date.parse(a.fm.date) : 0
        const db = b.fm.date ? Date.parse(b.fm.date) : 0
        return db - da
    })

    const projectEntries = projects.map(p => {
        const fields: string[] = [
            `    collection: ${JSON.stringify(p.collection)} as const`,
            `    slug: ${JSON.stringify(p.slug)}`,
            `    title: ${JSON.stringify(p.fm.title)}`,
        ]
        if (p.fm.shortTitle) fields.push(`    shortTitle: ${JSON.stringify(p.fm.shortTitle)}`)
        fields.push(`    description: ${JSON.stringify(p.fm.description)}`)
        fields.push(`    imageUrl: ${JSON.stringify(p.fm.thumbnail)}`)
        if (p.fm.heroImage) fields.push(`    heroImageSrc: ${JSON.stringify(p.fm.heroImage)}`)
        if (p.fm.heroAlt) fields.push(`    heroAlt: ${JSON.stringify(p.fm.heroAlt)}`)
        fields.push(`    gitUrl: ${JSON.stringify(p.fm.gitUrl)}`)
        if (p.fm.authors?.length) fields.push(`    authors: ${JSON.stringify(p.fm.authors)}`)
        if (p.fm.date) fields.push(`    date: ${JSON.stringify(p.fm.date)}`)
        if (p.fm.pdfUrl) fields.push(`    pdfUrl: ${JSON.stringify(p.fm.pdfUrl)}`)
        if (p.fm.demoUrl) fields.push(`    demoUrl: ${JSON.stringify(p.fm.demoUrl)}`)
        if (p.fm.featured) fields.push(`    featured: true`)
        if (p.fm.hideHero) fields.push(`    hideHero: true`)
        return `  {\n${fields.join(',\n')}\n  }`
    })

    const projectsTs = [
        '// AUTO-GENERATED by scripts/collect-projects.mts — do not edit',
        `import type { Project } from './types'`,
        '',
        `export const projectsData: Project[] = [`,
        projectEntries.join(',\n'),
        `]`,
        '',
    ].join('\n')

    const loaderEntries: string[] = []
    for (const p of projects) {
        loaderEntries.push(`  ${JSON.stringify(p.slug)}: () => import(${JSON.stringify(p.importPath)})`)
        if (p.canonicalKey !== p.slug) {
            loaderEntries.push(`  ${JSON.stringify(p.canonicalKey)}: () => import(${JSON.stringify(p.importPath)})`)
        }
    }

    const registryTs = [
        '// AUTO-GENERATED by scripts/collect-projects.mts — do not edit',
        `import type { Heading } from '@/types/content'`,
        `import type { ComponentType } from 'react'`,
        '',
        `type MdxModule = {`,
        `  default: ComponentType<Record<string, unknown>>`,
        `  headings?: Heading[]`,
        `}`,
        '',
        `export const projectsMdxLoaders: Record<string, () => Promise<MdxModule>> = {`,
        loaderEntries.join(',\n'),
        `}`,
        '',
    ].join('\n')

    fs.writeFileSync(PROJECTS_OUT, projectsTs, 'utf-8')
    fs.writeFileSync(REGISTRY_OUT, registryTs, 'utf-8')

    console.log(`Generated ${projects.length} projects`)
    console.log(`  ${PROJECTS_OUT}`)
    console.log(`  ${REGISTRY_OUT}`)
}

main()
